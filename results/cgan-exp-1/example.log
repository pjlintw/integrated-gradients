15:19:05, 721 __main__ INFO Namespace(batch_size=48, dataset_script='wiki-table-questions.py', do_eval=True, do_predict=True, do_train=True, eval_steps=10, gpu=False, logging_first_step='True', logging_steps=5, max_seq_length=20, max_steps=30, max_test_samples=200, max_train_samples=None, max_val_samples=200, mle_epochs=3, model_name_or_path='textgan', output_dir='results/cgan-exp-1', rnn_bidirectional=False, rnn_classes=1, rnn_dims=256, rnn_dropout_rate=0.1, rnn_embedding_dims=256, rnn_layers=1, tf_dims=512, tf_dropout_rate=0.1, tf_embedding_dims=256, tf_heads=8, tf_layers=2, tf_learning_rate=0.01, tf_shared_emb_layer=False, train_discriminator_epochs=1, vocab='data/wikiTable/word.vocab')
15:19:05, 721 __main__ INFO Saving hyperparameters to: results/cgan-exp-1/hyparams.txt
15:19:05, 730 datasets.builder WARNING Reusing dataset wiki_table_questions (/home/CE/pinjie/.cache/huggingface/datasets/wiki_table_questions/WikiTableQuestions/0.0.0/6a4116117d81a3d888218d55619bdb3ba81a1942ee880bf11b7f64a30e2f8e1a)
15:19:05, 743 __main__ INFO Loading Datasets
15:19:05, 753 root INFO PAD_IDX: 8133
15:19:08, 555 root INFO TransformerEncoder(
  (enc_layers): ModuleList(
    (0): TransformerEncLayer(
      (mha): MultiHeadAttention(
        (w_q): Linear(in_features=512, out_features=512, bias=True)
        (w_k): Linear(in_features=512, out_features=512, bias=True)
        (w_v): Linear(in_features=512, out_features=512, bias=True)
      )
      (ffn): FeedForwardBlock(
        (dense1): Linear(in_features=512, out_features=2048, bias=True)
        (relu): ReLU()
        (dense2): Linear(in_features=2048, out_features=512, bias=True)
      )
      (layernorm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (layernorm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
    )
    (1): TransformerEncLayer(
      (mha): MultiHeadAttention(
        (w_q): Linear(in_features=512, out_features=512, bias=True)
        (w_k): Linear(in_features=512, out_features=512, bias=True)
        (w_v): Linear(in_features=512, out_features=512, bias=True)
      )
      (ffn): FeedForwardBlock(
        (dense1): Linear(in_features=512, out_features=2048, bias=True)
        (relu): ReLU()
        (dense2): Linear(in_features=2048, out_features=512, bias=True)
      )
      (layernorm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (layernorm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
)
15:19:08, 630 root INFO CustomLSTM(
  (embedding): Embedding(11471, 300)
  (lstm): LSTM(300, 128, batch_first=True, bidirectional=True)
  (drop): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=256, out_features=1, bias=True)
)
15:19:21, 167 root INFO Model: generator, Step: 50, Loss: 7.67
15:19:34, 29 root INFO Model: generator, Step: 100, Loss: 6.10
15:19:46, 736 root INFO Model: generator, Step: 150, Loss: 5.13
15:19:59, 432 root INFO Model: generator, Step: 200, Loss: 4.92
15:20:23, 693 root INFO Model: generator, Step: 50, Loss: 4.48
15:20:36, 185 root INFO Model: generator, Step: 100, Loss: 4.03
15:20:48, 798 root INFO Model: generator, Step: 150, Loss: 4.00
15:21:01, 449 root INFO Model: generator, Step: 200, Loss: 4.08
15:21:25, 307 root INFO Model: generator, Step: 50, Loss: 3.64
15:21:37, 713 root INFO Model: generator, Step: 100, Loss: 3.63
15:21:50, 276 root INFO Model: generator, Step: 150, Loss: 3.74
15:22:02, 703 root INFO Model: generator, Step: 200, Loss: 3.53
15:22:14, 560 root INFO Step: 1, Classifcation Loss: 33.61, Classification Acc: 20.00
15:22:14, 560 root INFO Step: 1, Matching Loss: 33.52, Matching Acc: 23.00
15:22:15, 104 root INFO Step: 2, Classifcation Loss: 29.84, Classification Acc: 28.00
15:22:15, 104 root INFO Step: 2, Matching Loss: 30.74, Matching Acc: 31.00
15:22:15, 641 root INFO Step: 3, Classifcation Loss: 22.11, Classification Acc: 42.00
15:22:15, 642 root INFO Step: 3, Matching Loss: 23.72, Matching Acc: 36.00
15:22:16, 149 root INFO Step: 4, Classifcation Loss: 20.09, Classification Acc: 39.00
15:22:16, 149 root INFO Step: 4, Matching Loss: 18.84, Matching Acc: 43.00
15:22:16, 657 root INFO Step: 5, Classifcation Loss: 21.43, Classification Acc: 41.00
15:22:16, 657 root INFO Step: 5, Matching Loss: 21.14, Matching Acc: 38.00
15:22:17, 138 root INFO Step: 6, Classifcation Loss: 16.29, Classification Acc: 44.00
15:22:17, 138 root INFO Step: 6, Matching Loss: 12.35, Matching Acc: 44.00
15:22:17, 622 root INFO Step: 7, Classifcation Loss: 14.64, Classification Acc: 43.00
15:22:17, 623 root INFO Step: 7, Matching Loss: 10.47, Matching Acc: 45.00
15:22:18, 143 root INFO Step: 8, Classifcation Loss: 13.91, Classification Acc: 43.00
15:22:18, 143 root INFO Step: 8, Matching Loss: 11.76, Matching Acc: 43.00
15:22:18, 644 root INFO Step: 9, Classifcation Loss: 14.17, Classification Acc: 44.00
15:22:18, 644 root INFO Step: 9, Matching Loss: 9.28, Matching Acc: 44.00
15:22:19, 127 root INFO Step: 10, Classifcation Loss: 12.42, Classification Acc: 44.00
15:22:19, 127 root INFO Step: 10, Matching Loss: 8.07, Matching Acc: 45.00
15:22:19, 659 root INFO Step: 11, Classifcation Loss: 12.71, Classification Acc: 44.00
15:22:19, 660 root INFO Step: 11, Matching Loss: 4.79, Matching Acc: 47.00
15:22:20, 110 root INFO Step: 12, Classifcation Loss: 15.93, Classification Acc: 41.00
15:22:20, 110 root INFO Step: 12, Matching Loss: 14.08, Matching Acc: 43.00
15:22:20, 635 root INFO Step: 13, Classifcation Loss: 11.09, Classification Acc: 44.00
15:22:20, 636 root INFO Step: 13, Matching Loss: 4.79, Matching Acc: 47.00
15:22:21, 119 root INFO Step: 14, Classifcation Loss: 7.47, Classification Acc: 46.00
15:22:21, 119 root INFO Step: 14, Matching Loss: 4.53, Matching Acc: 47.00
15:22:21, 587 root INFO Step: 15, Classifcation Loss: 10.33, Classification Acc: 45.00
15:22:21, 588 root INFO Step: 15, Matching Loss: 4.31, Matching Acc: 47.00
15:22:22, 121 root INFO Step: 16, Classifcation Loss: 10.48, Classification Acc: 45.00
15:22:22, 121 root INFO Step: 16, Matching Loss: 9.41, Matching Acc: 45.00
15:22:22, 602 root INFO Step: 17, Classifcation Loss: 17.46, Classification Acc: 41.00
15:22:22, 602 root INFO Step: 17, Matching Loss: 3.62, Matching Acc: 46.00
15:22:23, 31 root INFO Step: 18, Classifcation Loss: 8.10, Classification Acc: 46.00
15:22:23, 31 root INFO Step: 18, Matching Loss: 3.60, Matching Acc: 47.00
15:22:23, 538 root INFO Step: 19, Classifcation Loss: 11.72, Classification Acc: 45.00
15:22:23, 539 root INFO Step: 19, Matching Loss: 7.42, Matching Acc: 45.00
15:22:23, 995 root INFO Step: 20, Classifcation Loss: 13.79, Classification Acc: 43.00
15:22:23, 995 root INFO Step: 20, Matching Loss: 8.35, Matching Acc: 46.00
15:22:24, 511 root INFO Step: 21, Classifcation Loss: 8.48, Classification Acc: 45.00
15:22:24, 512 root INFO Step: 21, Matching Loss: 2.50, Matching Acc: 48.00
15:22:24, 990 root INFO Step: 22, Classifcation Loss: 11.50, Classification Acc: 45.00
15:22:24, 990 root INFO Step: 22, Matching Loss: 1.50, Matching Acc: 48.00
15:22:25, 495 root INFO Step: 23, Classifcation Loss: 12.46, Classification Acc: 43.00
15:22:25, 495 root INFO Step: 23, Matching Loss: 0.76, Matching Acc: 48.00
15:22:26, 0 root INFO Step: 24, Classifcation Loss: 10.50, Classification Acc: 44.00
15:22:26, 0 root INFO Step: 24, Matching Loss: 9.30, Matching Acc: 47.00
15:22:26, 507 root INFO Step: 25, Classifcation Loss: 9.52, Classification Acc: 45.00
15:22:26, 507 root INFO Step: 25, Matching Loss: 0.67, Matching Acc: 48.00
15:22:27, 20 root INFO Step: 26, Classifcation Loss: 11.18, Classification Acc: 43.00
15:22:27, 20 root INFO Step: 26, Matching Loss: 1.77, Matching Acc: 47.00
15:22:27, 523 root INFO Step: 27, Classifcation Loss: 8.67, Classification Acc: 45.00
15:22:27, 523 root INFO Step: 27, Matching Loss: 3.21, Matching Acc: 46.00
15:22:28, 48 root INFO Step: 28, Classifcation Loss: 5.80, Classification Acc: 47.00
15:22:28, 48 root INFO Step: 28, Matching Loss: 1.33, Matching Acc: 48.00
15:22:28, 555 root INFO Step: 29, Classifcation Loss: 10.39, Classification Acc: 46.00
15:22:28, 555 root INFO Step: 29, Matching Loss: 4.91, Matching Acc: 47.00
15:22:28, 994 root INFO Step: 30, Classifcation Loss: 19.29, Classification Acc: 41.00
15:22:28, 994 root INFO Step: 30, Matching Loss: 0.83, Matching Acc: 48.00
