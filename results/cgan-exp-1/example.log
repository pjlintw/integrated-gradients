14:45:11, 148 __main__ INFO Namespace(batch_size=48, dataset_script='wiki-table-questions.py', do_eval=True, do_predict=True, do_train=True, eval_steps=10, gpu=False, logging_first_step='True', logging_steps=5, max_seq_length=20, max_steps=30, max_test_samples=200, max_train_samples=None, max_val_samples=200, mle_epochs=3, model_name_or_path='textgan', output_dir='results/cgan-exp-1', rnn_bidirectional=False, rnn_classes=1, rnn_dims=256, rnn_dropout_rate=0.1, rnn_embedding_dims=256, rnn_layers=1, tf_dims=512, tf_dropout_rate=0.1, tf_embedding_dims=256, tf_heads=8, tf_layers=2, tf_learning_rate=0.01, tf_shared_emb_layer=False, train_discriminator_epochs=1, vocab='data/wikiTable/word.vocab')
14:45:11, 149 __main__ INFO Saving hyperparameters to: results/cgan-exp-1/hyparams.txt
14:45:11, 158 datasets.builder WARNING Reusing dataset wiki_table_questions (/home/CE/pinjie/.cache/huggingface/datasets/wiki_table_questions/WikiTableQuestions/0.0.0/6a4116117d81a3d888218d55619bdb3ba81a1942ee880bf11b7f64a30e2f8e1a)
14:45:11, 171 __main__ INFO Loading Datasets
14:45:11, 181 root INFO PAD_IDX: 7582
14:45:13, 980 root INFO TransformerEncoder(
  (enc_layers): ModuleList(
    (0): TransformerEncLayer(
      (mha): MultiHeadAttention(
        (w_q): Linear(in_features=512, out_features=512, bias=True)
        (w_k): Linear(in_features=512, out_features=512, bias=True)
        (w_v): Linear(in_features=512, out_features=512, bias=True)
      )
      (ffn): FeedForwardBlock(
        (dense1): Linear(in_features=512, out_features=2048, bias=True)
        (relu): ReLU()
        (dense2): Linear(in_features=2048, out_features=512, bias=True)
      )
      (layernorm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (layernorm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
    )
    (1): TransformerEncLayer(
      (mha): MultiHeadAttention(
        (w_q): Linear(in_features=512, out_features=512, bias=True)
        (w_k): Linear(in_features=512, out_features=512, bias=True)
        (w_v): Linear(in_features=512, out_features=512, bias=True)
      )
      (ffn): FeedForwardBlock(
        (dense1): Linear(in_features=512, out_features=2048, bias=True)
        (relu): ReLU()
        (dense2): Linear(in_features=2048, out_features=512, bias=True)
      )
      (layernorm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (layernorm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
)
14:45:14, 55 root INFO CustomLSTM(
  (embedding): Embedding(11471, 300)
  (lstm): LSTM(300, 128, batch_first=True, bidirectional=True)
  (drop): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=256, out_features=1, bias=True)
)
14:45:26, 746 root INFO Model: generator, Step: 50, Loss: 7.69
14:45:39, 510 root INFO Model: generator, Step: 100, Loss: 6.15
14:45:52, 255 root INFO Model: generator, Step: 150, Loss: 5.08
14:46:04, 984 root INFO Model: generator, Step: 200, Loss: 4.68
14:46:29, 19 root INFO Model: generator, Step: 50, Loss: 4.03
14:46:41, 536 root INFO Model: generator, Step: 100, Loss: 4.00
14:46:54, 182 root INFO Model: generator, Step: 150, Loss: 4.09
14:47:06, 725 root INFO Model: generator, Step: 200, Loss: 3.94
14:47:30, 472 root INFO Model: generator, Step: 50, Loss: 3.56
14:47:42, 828 root INFO Model: generator, Step: 100, Loss: 3.42
14:47:55, 267 root INFO Model: generator, Step: 150, Loss: 3.90
14:48:07, 611 root INFO Model: generator, Step: 200, Loss: 3.41
14:48:19, 575 root INFO Step: 1, Classifcation Loss: 32.34, Classification Acc: 35.00
14:48:19, 576 root INFO Step: 1, Matching Loss: 33.11, Matching Acc: 26.00
14:48:20, 247 root INFO Step: 2, Classifcation Loss: 33.35, Classification Acc: 23.00
14:48:20, 247 root INFO Step: 2, Matching Loss: 27.79, Matching Acc: 35.00
14:48:20, 871 root INFO Step: 3, Classifcation Loss: 33.31, Classification Acc: 24.00
14:48:20, 871 root INFO Step: 3, Matching Loss: 20.33, Matching Acc: 41.00
14:48:21, 443 root INFO Step: 4, Classifcation Loss: 32.69, Classification Acc: 29.00
14:48:21, 443 root INFO Step: 4, Matching Loss: 17.25, Matching Acc: 39.00
14:48:22, 29 root INFO Step: 5, Classifcation Loss: 33.49, Classification Acc: 20.00
14:48:22, 29 root INFO Step: 5, Matching Loss: 18.39, Matching Acc: 39.00
14:48:22, 564 root INFO Step: 6, Classifcation Loss: 33.29, Classification Acc: 26.00
14:48:22, 564 root INFO Step: 6, Matching Loss: 19.33, Matching Acc: 39.00
14:48:23, 146 root INFO Step: 7, Classifcation Loss: 32.32, Classification Acc: 29.00
14:48:23, 147 root INFO Step: 7, Matching Loss: 10.92, Matching Acc: 43.00
14:48:23, 715 root INFO Step: 8, Classifcation Loss: 33.24, Classification Acc: 24.00
14:48:23, 715 root INFO Step: 8, Matching Loss: 11.28, Matching Acc: 43.00
14:48:24, 323 root INFO Step: 9, Classifcation Loss: 33.81, Classification Acc: 22.00
14:48:24, 323 root INFO Step: 9, Matching Loss: 20.08, Matching Acc: 40.00
14:48:24, 920 root INFO Step: 10, Classifcation Loss: 33.01, Classification Acc: 25.00
14:48:24, 920 root INFO Step: 10, Matching Loss: 15.57, Matching Acc: 43.00
14:48:25, 532 root INFO Step: 11, Classifcation Loss: 32.85, Classification Acc: 26.00
14:48:25, 532 root INFO Step: 11, Matching Loss: 6.71, Matching Acc: 48.00
14:48:26, 130 root INFO Step: 12, Classifcation Loss: 33.37, Classification Acc: 25.00
14:48:26, 130 root INFO Step: 12, Matching Loss: 8.85, Matching Acc: 45.00
14:48:26, 731 root INFO Step: 13, Classifcation Loss: 33.98, Classification Acc: 20.00
14:48:26, 732 root INFO Step: 13, Matching Loss: 7.92, Matching Acc: 44.00
14:48:27, 319 root INFO Step: 14, Classifcation Loss: 32.20, Classification Acc: 35.00
14:48:27, 319 root INFO Step: 14, Matching Loss: 4.88, Matching Acc: 47.00
14:48:27, 883 root INFO Step: 15, Classifcation Loss: 32.85, Classification Acc: 28.00
14:48:27, 883 root INFO Step: 15, Matching Loss: 7.42, Matching Acc: 45.00
14:48:28, 491 root INFO Step: 16, Classifcation Loss: 32.87, Classification Acc: 27.00
14:48:28, 491 root INFO Step: 16, Matching Loss: 5.67, Matching Acc: 45.00
14:48:29, 75 root INFO Step: 17, Classifcation Loss: 32.70, Classification Acc: 29.00
14:48:29, 75 root INFO Step: 17, Matching Loss: 2.92, Matching Acc: 47.00
14:48:29, 654 root INFO Step: 18, Classifcation Loss: 33.40, Classification Acc: 23.00
14:48:29, 655 root INFO Step: 18, Matching Loss: 4.70, Matching Acc: 46.00
14:48:30, 250 root INFO Step: 19, Classifcation Loss: 32.74, Classification Acc: 26.00
14:48:30, 251 root INFO Step: 19, Matching Loss: 6.14, Matching Acc: 46.00
14:48:30, 822 root INFO Step: 20, Classifcation Loss: 32.80, Classification Acc: 31.00
14:48:30, 823 root INFO Step: 20, Matching Loss: 1.70, Matching Acc: 48.00
14:48:31, 449 root INFO Step: 21, Classifcation Loss: 33.45, Classification Acc: 25.00
14:48:31, 449 root INFO Step: 21, Matching Loss: 6.78, Matching Acc: 46.00
14:48:32, 39 root INFO Step: 22, Classifcation Loss: 33.11, Classification Acc: 28.00
14:48:32, 40 root INFO Step: 22, Matching Loss: 1.94, Matching Acc: 48.00
14:48:32, 590 root INFO Step: 23, Classifcation Loss: 33.54, Classification Acc: 21.00
14:48:32, 590 root INFO Step: 23, Matching Loss: 10.25, Matching Acc: 46.00
14:48:33, 183 root INFO Step: 24, Classifcation Loss: 32.85, Classification Acc: 28.00
14:48:33, 183 root INFO Step: 24, Matching Loss: 4.20, Matching Acc: 47.00
14:48:33, 719 root INFO Step: 25, Classifcation Loss: 32.62, Classification Acc: 29.00
14:48:33, 719 root INFO Step: 25, Matching Loss: 3.70, Matching Acc: 47.00
14:48:34, 380 root INFO Step: 26, Classifcation Loss: 32.96, Classification Acc: 28.00
14:48:34, 380 root INFO Step: 26, Matching Loss: 1.54, Matching Acc: 48.00
14:48:35, 2 root INFO Step: 27, Classifcation Loss: 33.69, Classification Acc: 24.00
14:48:35, 3 root INFO Step: 27, Matching Loss: 1.76, Matching Acc: 47.00
14:48:35, 567 root INFO Step: 28, Classifcation Loss: 33.42, Classification Acc: 25.00
14:48:35, 568 root INFO Step: 28, Matching Loss: 1.19, Matching Acc: 48.00
14:48:36, 99 root INFO Step: 29, Classifcation Loss: 33.12, Classification Acc: 25.00
14:48:36, 99 root INFO Step: 29, Matching Loss: 1.88, Matching Acc: 48.00
14:48:36, 658 root INFO Step: 30, Classifcation Loss: 32.58, Classification Acc: 28.00
14:48:36, 658 root INFO Step: 30, Matching Loss: 1.86, Matching Acc: 48.00
